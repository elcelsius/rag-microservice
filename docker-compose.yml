services:
  ai_postgres:
    image: postgres:15-alpine
    container_name: ai_postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: ragdb
    volumes:
      - pgdata:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d ragdb"]
      interval: 10s
      timeout: 5s
      retries: 20
      start_period: 20s
    restart: unless-stopped

  ai_etl:
    # ConstrÃ³i o Ã­ndice FAISS e termina (exit 0 quando OK)
    build:
      context: .
      target: etl
    container_name: ai_etl
    environment:
      DATABASE_URL: "postgresql://postgres:postgres@ai_postgres:5432/ragdb"
      DATA_DIR: "/app/data/txt"
      FAISS_OUT_DIR: "/app/vector_store/faiss_index"
    depends_on:
      ai_postgres:
        condition: service_healthy
    volumes:
      - ./data:/app/data:ro
      - vector_store:/app/vector_store
    working_dir: /app
    # ðŸ‘‡ use python3 (nÃ£o 'python') para evitar exit 127
    command: ["bash", "-lc", "python3 -u scripts/etl_build_index.py && echo 'ETL done'"]
    restart: "no"

  ai_projeto_api:
    # API Flask que serve /query e /healthz
    build:
      context: .
      target: ai_api
    container_name: ai_projeto_api
    environment:
      FAISS_STORE_DIR: "/app/vector_store/faiss_index"
      # LLM (Google Gemini)
      GOOGLE_API_KEY: "${GOOGLE_API_KEY:-}"
      GOOGLE_MODEL:   "${GOOGLE_MODEL:-gemini-2.5-flash-lite}"
      # Health: exige LLM pronto para ficar "ready"? (true/false)
      REQUIRE_LLM_READY: "${REQUIRE_LLM_READY:-false}"
    depends_on:
      # sÃ³ sobe depois do ETL concluir com sucesso (Ã­ndice pronto no volume)
      ai_etl:
        condition: service_completed_successfully
    volumes:
      - vector_store:/app/vector_store
      - ./prompts:/app/prompts:ro
      - ./data:/app/data:ro
    ports:
      - "5000:5000"
    healthcheck:
      test: ["CMD", "python3", "-c", "import json,urllib.request,sys;u='http://127.0.0.1:5000/healthz';r=urllib.request.urlopen(u, timeout=3);d=json.loads(r.read().decode());sys.exit(0 if (d.get('ready') is True) else 1)"]
      interval: 10s
      timeout: 5s
      retries: 20
      start_period: 20s
    restart: unless-stopped

  ai_web_ui:
    image: nginx:1.29-alpine
    container_name: ai_web_ui
    depends_on:
      ai_projeto_api:
        condition: service_healthy
    ports:
      - "8080:80"
    volumes:
      # ajuste estes paths conforme sua Ã¡rvore local de UI
      - ./web_ui/html:/usr/share/nginx/html:ro
      - ./web_ui/nginx.default.conf:/etc/nginx/conf.d/default.conf:ro
    restart: unless-stopped

volumes:
  pgdata:
  vector_store:
