# üß† rag-microservice ‚Äî README FINAL (CPU + GPU) + ETL/RAG explicados

Microservi√ßo de **RAG (Retrieval-Augmented Generation)** com **Flask**, **FAISS**, **sentence-transformers** e UI via **nginx** (8080). Suporta **CPU** e **GPU (CUDA)**. Inclui **reranker** opcional (CrossEncoder).

---

## üì¶ Stack e servi√ßos

- **Python 3.11**
- **Flask** ‚Äî API (`/query`, `/healthz`)
- **LangChain (community + text-splitters)**
- **FAISS** ‚Äî √≠ndice vetorial persistente em `/app/vector_store/faiss_index`
- **Embeddings** ‚Äî `intfloat/multilingual-e5-large`
- **Reranker (opcional)** ‚Äî `jinaai/jina-reranker-v2-base-multilingual`
- **nginx** ‚Äî UI (8080) + proxy `/api/*` ‚Üí API (5000)
- Compose: `ai_etl` (ETL), `ai_projeto_api` (API), `ai_web_ui` (nginx/UI), `ai_postgres` (opcional)

---

## üóÇ Estrutura do reposit√≥rio (essencial)

```
rag-microservice/
‚îú‚îÄ config/ontology/terms.yml         # ontologia/dicion√°rio para triagem/normaliza√ß√£o
‚îú‚îÄ data/                             # documentos (TXT/MD/PDF/DOCX...), subpastas ok
‚îú‚îÄ loaders/                          # seus loaders: load(file_path)->list[Document]
‚îÇ  ‚îú‚îÄ code_loader.py                 # TextLoader com fallback de encoding
‚îÇ  ‚îú‚îÄ docx_loader.py                 # Docx2txtLoader / python-docx
‚îÇ  ‚îú‚îÄ md_loader.py                   # UnstructuredMarkdownLoader
‚îÇ  ‚îú‚îÄ pdf_loader.py                  # UnstructuredPDFLoader (mode="single")
‚îÇ  ‚îî‚îÄ txt_loader.py                  # TextLoader
‚îú‚îÄ prompts/
‚îÇ  ‚îú‚îÄ pedir_info_prompt.txt
‚îÇ  ‚îú‚îÄ resposta_final_prompt.txt
‚îÇ  ‚îî‚îÄ triagem_prompt.txt
‚îú‚îÄ scripts/
‚îÇ  ‚îú‚îÄ etl_build_index.py             # ETL (CLI: --data, --out, --exts, --loaders, ...)
‚îÇ  ‚îú‚îÄ treinar_ia_cpu.sh / treinar_ia_gpu.sh
‚îÇ  ‚îú‚îÄ inicia_site_cpu.sh / inicia_site_gpu.sh
‚îÇ  ‚îú‚îÄ smoke_cpu.sh / smoke_gpu.sh
‚îÇ  ‚îî‚îÄ (outros auxiliares)
‚îú‚îÄ web_ui/
‚îÇ  ‚îú‚îÄ html/index.html                # usa /api/query e /api/healthz
‚îÇ  ‚îî‚îÄ conf.d/default.conf            # nginx mapeia /api/* -> ai_projeto_api:5000
‚îú‚îÄ api.py                            # Flask app (endpoints)
‚îú‚îÄ query_handler.py                  # RAG + reranker + debug/telemetria
‚îî‚îÄ docker-compose.*.yml
```

---

## üîß Vari√°veis (API)

- `FAISS_STORE_DIR=/app/vector_store/faiss_index`
- `EMBEDDINGS_MODEL=intfloat/multilingual-e5-large`
- `RERANKER_ENABLED=true|false`
- `RERANKER_NAME=jinaai/jina-reranker-v2-base-multilingual`
- `RERANKER_TOP_K=5`
- `RERANKER_MAX_LEN=512`
- `REQUIRE_LLM_READY=false`

---

## ‚ñ∂Ô∏è Executar scripts a partir da raiz

### Linux/macOS
```bash
chmod +x scripts/*.sh
./scripts/treinar_ia_cpu.sh
./scripts/inicia_site_cpu.sh
# GPU se aplic√°vel
./scripts/treinar_ia_gpu.sh
./scripts/inicia_site_gpu.sh
# smokes
./smoke_cpu.sh
./smoke_gpu.sh
```

### Windows
- Prefer√≠vel usar **WSL** (Ubuntu) e os comandos acima.
- PowerShell (fora do WSL): use `bash`:
```powershell
bash scripts/treinar_ia_cpu.sh
bash scripts/inicia_site_cpu.sh
bash smoke_cpu.sh
```

> Se aparecer **permission denied** ‚Üí `chmod +x scripts/*.sh`  
> Se aparecer **bad interpreter / ^M** ‚Üí `dos2unix scripts/*.sh` (CRLF ‚Üí LF)  
> Se `docker-compose` n√£o existir ‚Üí use `docker compose` (v2).

---

## üöÄ Subir servi√ßos

### CPU
```bash
./scripts/treinar_ia_cpu.sh         # roda ETL (gera FAISS a partir de ./data)
./scripts/inicia_site_cpu.sh        # sobe API+Web
curl -s http://localhost:8080/api/healthz | jq .
```

### GPU (CUDA)
```bash
./scripts/treinar_ia_gpu.sh
./scripts/inicia_site_gpu.sh
curl -s http://localhost:8080/api/healthz | jq .
```

---

## üß™ Smokes (CPU/GPU) com flags

```bash
# CPU b√°sico
./smoke_cpu.sh

# CPU com ETL e CSV/JSON (se voc√™ tiver loaders read_csv/read_json)
./smoke_cpu.sh --with-etl --exts "txt,md,pdf,docx,csv,json" --loaders ./loaders \
  --question "onde encontro informa√ß√£o de monitoria de computa√ß√£o?"

# GPU b√°sico
./smoke_gpu.sh

# GPU com ETL e as mesmas extens√µes
./smoke_gpu.sh --with-etl --exts "txt,md,pdf,docx,csv,json" --loaders ./loaders
```

Os smokes validam:
- `ready:true` e `faiss:true` no `/api/healthz`
- resposta via 5000 e 8080
- (se reranker ativo) **scores num√©ricos** (sem `null`).

---

## üß© Como funciona o **ETL** neste projeto

O ETL √© respons√°vel por **preparar a base vetorial** usada nas buscas do RAG.

### Passo a passo
1. **Leitura de arquivos** (recursiva) em `./data` filtrando por extens√µes suportadas (`--exts`).  
2. **Loaders** (prioridade dupla):
   - **Estilo ‚Äúread_\<ext\>‚Äù**: se existir uma fun√ß√£o `read_<ext>(path)` em `loaders/`, ela √© usada, retornando **texto** (`str`). Ex.: `read_csv`, `read_json`.
   - **Estilo ‚Äúload(file_path)‚Äù**: se existir uma fun√ß√£o `load(file_path) -> list[Document]` (seus loaders), o ETL **concatena** os `page_content` dos `Document` e segue.  
   - Se nenhum desses estiver dispon√≠vel, usa **leitores nativos** de texto (txt/md/pdf/docx) como fallback.
3. **Chunking** com `RecursiveCharacterTextSplitter` (par√¢metros `--chunk-size` e `--chunk-overlap`).  
4. **Embeddings**: cada chunk vira um vetor usando `intfloat/multilingual-e5-large` (padr√£o).  
5. **FAISS**: os vetores + metadados (`source`, `chunk`) s√£o gravados em `/app/vector_store/faiss_index` (ou caminho passado com `--out`).

### Diagrama (alto n√≠vel)
```
./data  ‚îÄ‚îÄ‚ñ∫ (loaders) read_<ext> | load(file) | fallback ‚îÄ‚îÄ‚ñ∫ texto √∫nico
                                         ‚îÇ
                                  split em chunks
                                         ‚îÇ
                               embeddings (e5-large)
                                         ‚îÇ
                          FAISS (persistido em volume docker)
```

> Resultado: a API consegue fazer busca vetorial **r√°pida** sem depender do tempo de parsing/embedding a cada pergunta.

---

## üîé Como funciona o **RAG** (pipeline de consulta)

Quando voc√™ chama `POST /query` (via 5000) ou `POST /api/query` (via 8080):

1. **Triagem / Roteamento** (conforme seus prompts e regras internas):  
   Decide a rota (ex.: lexical vs. vetorial). No seu caso, a rota **lexical** vem aparecendo no debug; a rota vetorial usa FAISS.
2. **Busca (FAISS)**:  
   - A pergunta √© embeddada com o mesmo modelo (`e5-large`).  
   - O FAISS retorna os **k** chunks mais pr√≥ximos (candidatos).  
   - O tempo √© registrado em `debug.timing_ms.retrieval` (quando `debug=true`).
3. **Reranker (opcional)**:  
   - Se `RERANKER_ENABLED=true`, o CrossEncoder pontua os pares `(pergunta, chunk)` e reordena.  
   - Se o modelo n√£o estiver dispon√≠vel ou falhar, o backend cai em **fallback** (scores `0.0`, `enabled=false`).  
   - O tempo √© registrado em `debug.timing_ms.reranker`.
4. **S√≠ntese/Resposta**:  
   - O sistema sintetiza um **resumo** usando os melhores trechos (com ou sem reranker).  
   - As **fontes** saem em `citations` (cada item com `source`, `chunk`, `preview`).  
   - `context_found` indica se havia contexto √∫til.
5. **Seguran√ßa de debug**:  
   - `debug.rerank.scored[*].score` √© **sempre float** (0.0 no fallback), nunca `null` ‚Äî evita erros no front.

### Diagrama
```
pergunta ‚îÄ‚ñ∫ (triagem) ‚îÄ‚ñ∫ (FAISS top-k) ‚îÄ‚ñ∫ (reranker?) ‚îÄ‚ñ∫ resposta + cita√ß√µes
                        ‚îÇ                ‚îÇ
                        ‚îî‚îÄ‚îÄ timing_ms.retrieval   timing_ms.reranker
```

---

## ‚úÖ Checklist r√°pido de valida√ß√£o

- `curl -s http://localhost:8080/api/healthz | jq .` ‚Üí `ready:true`, `faiss:true`  
- `POST /api/query` retorna `answer` + `citations`  
- (se ativo) `debug.rerank.enabled:true` e `score` **num√©rico**  
- Logs limpos (`docker logs -f ai_projeto_api`)

---

## üß∞ Troubleshooting
- **`ready:false`/`faiss:false`** ‚Üí rode ETL e verifique `FAISS_STORE_DIR` no container da API.  
- **Reranker lento** ‚Üí `RERANKER_ENABLED=false` ou reduza `RERANKER_TOP_K`.  
- **Timeout via 8080** ‚Üí confira `web_ui/conf.d/default.conf` (`location /api/`).  
- **CRLF em scripts** ‚Üí `dos2unix scripts/*.sh`.  
- **Sem internet para modelos** ‚Üí use cache local (`HF_HOME`/`TRANSFORMERS_CACHE`) ou desative o reranker.

---

## üìÑ Licen√ßa
MIT (ou a da sua organiza√ß√£o).

---

## üôå Cr√©ditos
- Projeto e organiza√ß√£o: Celso Lisboa  
- Patches de robustez (scores, timing, readiness) + documenta√ß√£o: colabora√ß√£o assistida
