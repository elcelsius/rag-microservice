# ü§ñ AI Copilot - Servi√ßo de ETL e RAG Gen√©rico

Este projeto implementa um pipeline completo de **Retrieval-Augmented Generation (RAG)**, projetado para servir como o n√∫cleo de um copiloto de IA para sistemas web complexos.

O objetivo √© **ler, processar e indexar** uma base de conhecimento privada (documenta√ß√£o, c√≥digo-fonte, etc.) e fornecer uma interface de consulta inteligente, capaz de responder perguntas complexas com alta precis√£o, utilizando a API do **Google Gemini**.

O sistema √© otimizado para ambientes com **GPU NVIDIA**, mas √© totalmente compat√≠vel com ambientes **apenas com CPU** atrav√©s de scripts dedicados.

---

## üìã Principais Funcionalidades
- **Pipeline de ETL Inteligente**: Suporta m√∫ltiplos formatos de arquivo e oferece dois modos de treinamento: rebuild completo ou atualiza√ß√£o incremental (apenas para arquivos novos).
- **Base de Conhecimento Vetorial**: Utiliza *sentence-transformers* para gerar embeddings e **FAISS** para busca vetorial eficiente.
- **Portabilidade CPU/GPU**: Ambiente containerizado com suporte expl√≠cito para execu√ß√£o acelerada por **CUDA** ou em modo **CPU-only**.
- **Persist√™ncia de Metadados**: Armazenamento de chunks e rastreamento de arquivos processados em **PostgreSQL**.
- **Agente de IA com LangGraph**: Um agente inteligente avalia as perguntas antes de agir, decidindo entre responder ou pedir mais informa√ß√µes.
- **Gera√ß√£o de Respostas com LLM**: Integra√ß√£o com a API do **Google Gemini**, com modelo configur√°vel via vari√°veis de ambiente.

---

## üõ†Ô∏è Stack de Tecnologias
- **Linguagem**: Python 3.11
- **Orquestra√ß√£o**: Docker & Docker Compose
- **IA & Machine Learning**:
  - LangChain, LangGraph
  - Sentence Transformers (*all-MiniLM-L6-v2*)
  - FAISS-GPU / FAISS-CPU
  - PyTorch
  - Google Generative AI (Gemma, Gemini)
- **Banco de Dados**: PostgreSQL 15
- **Ambiente Base**: Imagem NVIDIA CUDA (GPU) ou Python Slim (CPU)

---

## üöÄ Configura√ß√£o do Ambiente

### ‚úÖ Pr√©-requisitos
- Git
- Docker Desktop
- WSL2 (para usu√°rios Windows)
- **Para modo GPU**: Drivers NVIDIA com suporte a CUDA instalados no host.

### üîß Instala√ß√£o
1. Clone o reposit√≥rio:
   ```bash
   git clone [https://github.com/elcelsius/ai_etl_project.git](https://github.com/elcelsius/ai_etl_project.git)
   cd ai_etl_project
Configure as vari√°veis de ambiente (copie .env.example para .env e preencha sua GOOGLE_API_KEY).

Adicione seus arquivos de documenta√ß√£o na pasta data/.

D√™ permiss√£o de execu√ß√£o para os scripts:

Bash

chmod +x *.sh
üí° Fluxo de Trabalho (Como Usar)
Escolha o ambiente de acordo com seu hardware.

Op√ß√£o 1: Ambiente com GPU NVIDIA (Recomendado)
Use os scripts com o sufixo _gpu.

Para treinar a IA:

Bash

# Rebuild completo (lento, apaga tudo e refaz)
./treinar_ia_gpu.sh

# Atualiza√ß√£o incremental (r√°pido, adiciona somente arquivos novos)
./treinar_ia_gpu.sh --update
Para iniciar o site e conversar pela interface web:

Bash

./inicia_site_gpu.sh
Para conversar pelo terminal:

Bash

./ai_etl_conv_term_gpu.sh
Op√ß√£o 2: Ambiente Apenas com CPU
Use os scripts com o sufixo _cpu.

Para treinar a IA:

Bash

# Rebuild completo (lento, apaga tudo e refaz)
./treinar_ia_cpu.sh

# Atualiza√ß√£o incremental (r√°pido, adiciona somente arquivos novos)
./treinar_ia_cpu.sh --update
Para iniciar o site e conversar pela interface web:

Bash

./inicia_site_cpu.sh
Para conversar pelo terminal:

Bash

./ai_etl_conv_term_cpu.sh
‚úçÔ∏è Autor: Celso Lisboa
üìé Reposit√≥rio: github.com/elcelsius/ai_etl_project
