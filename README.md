# üß† rag-microservice ‚Äî README Completo (CPU + GPU)

Microservi√ßo de **RAG (Retrieval-Augmented Generation)** com **Flask**, **FAISS**, **sentence-transformers** e UI est√°tica via **nginx**. Suporta **CPU** e **GPU (CUDA)**. Inclui **reranker** opcional (CrossEncoder) e health-checks prontos para front-end.

---

## üì¶ Vis√£o geral da stack

- **Python 3.11**
- **Flask** ‚Äî API (`/query`, `/healthz`)
- **LangChain (community + text-splitters)** ‚Äî split de textos
- **FAISS** ‚Äî √≠ndice vetorial persistido em `/app/vector_store/faiss_index`
- **Embeddings** ‚Äî `intfloat/multilingual-e5-large` (Hugging Face)
- **Reranker opcional** ‚Äî `jinaai/jina-reranker-v2-base-multilingual` (CrossEncoder)
- **nginx** ‚Äî serve UI (8080) e proxy para API (`/api/*` ‚Üí 5000)

Containers (CPU): `ai_etl`, `ai_projeto_api`, `ai_web_ui`, `ai_postgres` (opcional).

---

## üóÇ Estrutura de diret√≥rios (essencial)

```
rag-microservice/
‚îú‚îÄ config/
‚îÇ  ‚îî‚îÄ ontology/terms.yml        # dicion√°rio/ontologia de termos
‚îú‚îÄ data/                        # base de documentos (TXT/MD/PDF/DOCX), com subpastas
‚îú‚îÄ loaders/                     # leitores personalizados por tipo (code/docx/md/pdf/txt)
‚îú‚îÄ prompts/                     # moldam o fluxo de resposta
‚îÇ  ‚îú‚îÄ pedir_info_prompt.txt
‚îÇ  ‚îú‚îÄ resposta_final_prompt.txt
‚îÇ  ‚îî‚îÄ triagem_prompt.txt
‚îú‚îÄ scripts/
‚îÇ  ‚îú‚îÄ etl_build_index.py        # ETL que gera √≠ndice FAISS
‚îÇ  ‚îú‚îÄ inicia_site_cpu.sh        # sobe tudo (CPU) + abre UI
‚îÇ  ‚îú‚îÄ inicia_site_gpu.sh        # sobe tudo (GPU) + abre UI
‚îÇ  ‚îú‚îÄ treinar_ia_cpu.sh         # executa ETL (CPU)
‚îÇ  ‚îî‚îÄ treinar_ia_gpu.sh         # executa ETL (GPU)
‚îú‚îÄ web_ui/
‚îÇ  ‚îú‚îÄ html/index.html           # UI: usa /api/query e /api/healthz
‚îÇ  ‚îî‚îÄ conf.d/default.conf       # nginx: /api/* ‚Üí ai_projeto_api:5000
‚îú‚îÄ api.py                       # Flask app (endpoints)
‚îú‚îÄ query_handler.py             # RAG + reranker + debug/telemetria
‚îî‚îÄ docker-compose.*.yml         # orquestra√ß√£o CPU/GPU
```

**Papel das pastas-chave**  
- `config/ontology/terms.yml`: dicion√°rio/ontologia de termos usados para triagem ou normaliza√ß√£o de entidades/consultas.  
- `data/`: fontes de conhecimento; pode ter **subpastas**. O ETL l√™ recursivamente.  
- `loaders/`: leitores por tipo ‚Äî cada `*_loader.py` implementa extra√ß√£o de texto para seu formato.  
- `prompts/`: textos dos prompts do pipeline (`triagem`, `pedir_info`, `resposta_final`).  
- `scripts/`: automa√ß√µes para iniciar servi√ßos e executar ETL.

---

## üîß Vari√°veis de ambiente (API)

No servi√ßo `ai_projeto_api`:

- `FAISS_STORE_DIR=/app/vector_store/faiss_index`
- `EMBEDDINGS_MODEL=intfloat/multilingual-e5-large`
- `RERANKER_ENABLED=true|false`
- `RERANKER_NAME=jinaai/jina-reranker-v2-base-multilingual`
- `RERANKER_TOP_K=5`
- `RERANKER_MAX_LEN=512`
- `REQUIRE_LLM_READY=false` (evita travar o healthz em LLM externo)

> Dica: se o reranker n√£o for necess√°rio (ou se a m√°quina √© limitada), use `RERANKER_ENABLED=false` ‚Äî o backend faz fallback seguro com `score=0.0`.

---

## üèó ETL (constru√ß√£o do √≠ndice)

O ETL percorre `./data`, l√™ arquivos suportados, divide em chunks e gera embeddings, salvando um √≠ndice **FAISS** persistente.  
- Script principal: `scripts/etl_build_index.py` (executado nos containers `ai_etl`).  
- Par√¢metros (via env): `DATA_DIR` (padr√£o `/app/data`), `FAISS_OUT_DIR` (padr√£o `/app/vector_store/faiss_index`), `EMBEDDINGS_MODEL`.

**CPU**:
```bash
docker-compose -f docker-compose.cpu.yml build ai_etl
docker-compose -f docker-compose.cpu.yml run --rm ai_etl \
  python scripts/etl_build_index.py --data ./data --out /app/vector_store/faiss_index
```

**GPU** (se preferir rodar ETL igual, tamb√©m funciona em CPU; GPU √© opcional):
```bash
docker-compose -f docker-compose.gpu.yml build ai_etl
docker-compose -f docker-compose.gpu.yml run --rm ai_etl \
  python scripts/etl_build_index.py --data ./data --out /app/vector_store/faiss_index
```

---

## üöÄ Subir servi√ßos

### CPU
Op√ß√£o A (scripts prontos):
```bash
./scripts/treinar_ia_cpu.sh      # roda ETL
./scripts/inicia_site_cpu.sh     # sobe API+Web e abre navegador
```

Op√ß√£o B (compose manual):
```bash
docker-compose -f docker-compose.cpu.yml build ai_projeto_api ai_web_ui
docker-compose -f docker-compose.cpu.yml up -d ai_projeto_api ai_web_ui
```

### GPU (CUDA)
Pr√©-requisitos: driver NVIDIA + NVIDIA Container Toolkit.

Op√ß√£o A (scripts prontos):
```bash
./scripts/treinar_ia_gpu.sh      # roda ETL
./scripts/inicia_site_gpu.sh     # sobe API+Web (GPU) e abre navegador
```

Op√ß√£o B (compose manual):
```bash
docker-compose -f docker-compose.gpu.yml build ai_projeto_api ai_web_ui
docker-compose -f docker-compose.gpu.yml up -d ai_projeto_api ai_web_ui
```

---

## üß™ Smoke tests

**Via script**:
```bash
./smoke.sh               # CPU (consulta via 5000 e 8080)
```

**Manual r√°pido**:

- Healthz:
```bash
curl -s http://localhost:5000/healthz | jq .
curl -s http://localhost:8080/api/healthz | jq .
```

- Consulta (5000) com debug:
```bash
curl -s -H "Content-Type: application/json" \
  -d '{"question":"onde encontro informa√ß√£o de monitoria de computa√ß√£o?","debug":true}' \
  http://localhost:5000/query | jq '.context_found, .debug.route, .debug.rerank.enabled, .debug.timing_ms'
```

- Consulta (8080) via nginx:
```bash
curl -s -H "Content-Type: application/json" \
  -d '{"question":"onde encontro informa√ß√£o de monitoria de computa√ß√£o?","debug":false}' \
  http://localhost:8080/api/query | jq '.answer, .citations'
```

- UI: acesse `http://localhost:8080/`  
  - Bot√£o **Perguntar** habilita somente quando `/api/healthz` retornar `ready:true`.

---

## üîç Valida√ß√£o funcional (checklist)

1. **ETL/FAISS**
   - √çndice criado no volume (`/app/vector_store/faiss_index`).
   - `healthz` retorna `"faiss": true` e `faiss_store_dir` correto.
2. **Embeddings**
   - `healthz` mostra `embeddings_model` esperado.
   - `context_found: true` quando h√° documentos relevantes em `./data`.
3. **Reranker (opcional)**
   - Se ativo, `debug.rerank.enabled: true` e `name` correto.
   - Scores **sempre float** (0.0 em fallback).
4. **Telemetria**
   - `debug.timing_ms.retrieval` e `debug.timing_ms.reranker` (quando aplic√°vel).
5. **nginx/UI**
   - `GET /api/healthz` (8080) ‚Üí 200 com `ready:true`.
   - `POST /api/query` ‚Üí 200 e resposta com `answer` + `citations`.
6. **Logs**
   - `docker logs -f ai_projeto_api` sem tracebacks.
   - Se o reranker falhar, WARN + fallback (sem quebrar).

---

## üß© Sobre *ontology*, *loaders* e *prompts*

- **Ontology (`config/ontology/terms.yml`)**: mantenha termos e aliases mapeados para normaliza√ß√£o/triagem. Um rebuild do ETL **n√£o** √© obrigat√≥rio ao editar a ontologia, a menos que gere novos metadados que precisem ir ao √≠ndice.
- **Loaders (`loaders/*.py`)**: cada loader extrai **texto** de um tipo de arquivo; o ETL utiliza fun√ß√µes equivalentes internamente (TXT/MD/PDF/DOCX). Se ampliar tipos, adicione novo loader e ajuste o ETL, se necess√°rio.
- **Prompts (`prompts/*.txt`)**:  
  - `triagem_prompt.txt` ‚Äî ajuda a decidir a rota/estrat√©gia de resposta.  
  - `pedir_info_prompt.txt` ‚Äî pedido de dados adicionais ao usu√°rio.  
  - `resposta_final_prompt.txt` ‚Äî molda a resposta final.  
  Ajuste com cuidado; mudan√ßas tendem a afetar estilo/estrutura das respostas.

---

## ‚ö° GPU: checagens r√°pidas

Verifique CUDA dentro do container da API:
```bash
docker-compose -f docker-compose.gpu.yml exec ai_projeto_api python - <<'PY'
import torch
print("torch.cuda.is_available:", torch.cuda.is_available())
print("num_gpus:", torch.cuda.device_count())
if torch.cuda.is_available():
    print("device:", torch.cuda.get_device_name(0))
PY
```

Se faltar VRAM ou houver erro, reduza `RERANKER_TOP_K` ou desative o reranker.

---

## üß∞ Troubleshooting

- **`ready=false`/`faiss=false`** ‚Üí rode o ETL; confirme `FAISS_STORE_DIR` na API.
- **Timeout via 8080** ‚Üí confira `web_ui/conf.d/default.conf` (`location /api/` para a API).
- **Reranker lento/falhando** ‚Üí `RERANKER_ENABLED=false` ou `TOP_K` menor; o backend j√° faz fallback seguro.
- **Compara√ß√£o de `None`** ‚Üí j√° mitigado (scores sempre float). Se aparecer, verifique se voc√™ alterou o front para n√£o ordenar por campos inexistentes.
- **Sem internet p/ baixar modelos** ‚Üí use cache local (`HF_HOME`/`TRANSFORMERS_CACHE`) ou desative o reranker.

---

## üìÑ Licen√ßa
MIT (ou a pol√≠tica da sua organiza√ß√£o).

---

## üôå Cr√©ditos
- Estrutura e ajustes do projeto: Celso Lisboa
- Patches de robustez (reranker, readiness, nginx/UI): colabora√ß√£o assistida
