services:
  ai_postgres:
    image: postgres:15-alpine
    container_name: ai_postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: ragdb
    volumes:
      - pgdata:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d ragdb"]
      interval: 10s
      timeout: 5s
      retries: 20
      start_period: 20s
    restart: unless-stopped

  ai_etl:
    build:
      context: .
      dockerfile: Dockerfile.gpu
      # target: etl   # <-- deixe comentado se não houver estágio "AS etl"
    container_name: ai_etl
    environment:
      DATABASE_URL: "postgresql://postgres:postgres@ai_postgres:5432/ragdb"
      DATA_DIR: "/app/data"
      FAISS_OUT_DIR: "/app/vector_store/faiss_index"
      EMBEDDINGS_MODEL: "${EMBEDDINGS_MODEL:-intfloat/multilingual-e5-large}"
    depends_on:
      ai_postgres:
        condition: service_healthy
    volumes:
      - ./data:/app/data:ro
      - vector_store:/app/vector_store
    working_dir: /app
    command: ["bash", "-lc", "python3 -u scripts/etl_build_index.py && echo 'ETL done'"]
    restart: "no"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  ai_projeto_api:
    build:
      context: .
      dockerfile: Dockerfile.gpu
      # target: ai_api  # <-- deixe comentado se não houver estágio "AS ai_api"
    container_name: ai_projeto_api
    environment:
      FAISS_STORE_DIR: "/app/vector_store/faiss_index"
      EMBEDDINGS_MODEL: "${EMBEDDINGS_MODEL:-intfloat/multilingual-e5-large}"
      GOOGLE_API_KEY: "${GOOGLE_API_KEY:-}"
      GOOGLE_MODEL:   "${GOOGLE_MODEL:-gemini-2.5-flash-lite}"
      REQUIRE_LLM_READY: "${REQUIRE_LLM_READY:-false}"
    depends_on:
      ai_etl:
        condition: service_completed_successfully
    volumes:
      - vector_store:/app/vector_store
      - ./prompts:/app/prompts:ro
      - ./data:/app/data:ro
    ports:
      - "5000:5000"
    healthcheck:
      test: ["CMD", "python3", "-c", "import json,urllib.request,sys; d=json.loads(urllib.request.urlopen('http://localhost:5000/healthz').read().decode()); sys.exit(0 if (d.get('ready') is True) else 1)"]
      interval: 10s
      timeout: 5s
      retries: 20
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  ai_web_ui:
    image: nginx:1.27-alpine
    container_name: ai_web_ui
    depends_on:
      ai_projeto_api:
        condition: service_healthy
    ports:
      - "8080:80"
    volumes:
      - ./web_ui/html:/usr/share/nginx/html:ro
      - ./web_ui/conf.d:/etc/nginx/conf.d:ro
    restart: unless-stopped

volumes:
  pgdata:
  vector_store:
