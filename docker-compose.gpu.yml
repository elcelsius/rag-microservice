services:
  ai_postgres:
    image: postgres:15-alpine
    container_name: ai_postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: ragdb
    volumes:
      - pgdata:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d ragdb"]
      interval: 10s
      timeout: 5s
      retries: 20
      start_period: 20s
    restart: unless-stopped

  ai_etl:
    build:
      context: .
      dockerfile: Dockerfile.gpu
      # target: etl   # <-- deixe comentado se não houver estágio "AS etl"
    container_name: ai_etl
    environment:
      CUDA_VISIBLE_DEVICES: ""   # <— força CPU no ETL
      DATABASE_URL: "postgresql://postgres:postgres@ai_postgres:5432/ragdb"
      DATA_DIR: "/app/data"
      FAISS_OUT_DIR: "/app/vector_store/faiss_index"
      EMBEDDINGS_MODEL: "${EMBEDDINGS_MODEL:-intfloat/multilingual-e5-large}"
      RERANKER_ENABLED: "${RERANKER_ENABLED:-true}"
      RERANKER_NAME: "${RERANKER_NAME:-jinaai/jina-reranker-v2-base-multilingual}"
      RERANKER_CANDIDATES: "${RERANKER_CANDIDATES:-30}"
      RERANKER_TOP_K: "${RERANKER_TOP_K:-5}"
      RERANKER_MAX_LEN: "${RERANKER_MAX_LEN:-4096}"
      MQ_ENABLED: "${MQ_ENABLED:-true}"
      MQ_VARIANTS: "${MQ_VARIANTS:-3}"
      CONFIDENCE_MIN: "${CONFIDENCE_MIN:-0.32}"
      REQUIRE_CONTEXT: "${REQUIRE_CONTEXT:-true}"
    depends_on:
      ai_postgres:
        condition: service_healthy
    volumes:
      - ./data:/app/data:ro
      - vector_store:/app/vector_store
      - ./config:/app/config:ro
    working_dir: /app
    command: ["bash", "-lc", "python3 -u scripts/etl_build_index.py && echo 'ETL done'"]
    restart: "no"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  ai_projeto_api:
    build:
      context: .
      dockerfile: Dockerfile.gpu
      # target: ai_api  # <-- deixe comentado se não houver estágio "AS ai_api"
    container_name: ai_projeto_api
    environment:
      FAISS_STORE_DIR: "/app/vector_store/faiss_index"
      EMBEDDINGS_MODEL: "${EMBEDDINGS_MODEL:-intfloat/multilingual-e5-large}"
      GOOGLE_API_KEY: "${GOOGLE_API_KEY:-}"
      GOOGLE_MODEL:   "${GOOGLE_MODEL:-gemini-2.5-flash-lite}"
      REQUIRE_LLM_READY: "${REQUIRE_LLM_READY:-false}"
      STRUCTURED_ANSWER: "${STRUCTURED_ANSWER:-true}"
      MAX_SOURCES: "${MAX_SOURCES:-5}"
      DEBUG_LOG: "${DEBUG_LOG:-true}"         # logar no stdout
      DEBUG_PAYLOAD: "${DEBUG_PAYLOAD:-true}" # incluir "debug" na resposta quando ?debug=true
    depends_on:
      ai_etl:
        condition: service_completed_successfully
    volumes:
      - vector_store:/app/vector_store
      - ./prompts:/app/prompts:ro
      - ./data:/app/data:ro
      - ./config:/app/config:ro
    ports:
      - "5000:5000"
    healthcheck:
      test: ["CMD", "python3", "-c", "import json,urllib.request,sys; d=json.loads(urllib.request.urlopen('http://localhost:5000/healthz').read().decode()); sys.exit(0 if (d.get('ready') is True) else 1)"]
      interval: 10s
      timeout: 5s
      retries: 20
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  ai_web_ui:
    image: nginx:1.27-alpine
    container_name: ai_web_ui
    depends_on:
      ai_projeto_api:
        condition: service_healthy
    ports:
      - "8080:80"
    volumes:
      - ./web_ui/html:/usr/share/nginx/html:ro
      - ./web_ui/conf.d:/etc/nginx/conf.d:ro
    restart: unless-stopped

volumes:
  pgdata:
  vector_store:
